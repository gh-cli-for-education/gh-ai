# gh-ai conversation log 

This file has been created by the program gh-ai, therefore it does not entail any increase in token usage. The objective of this markdown file is to store the input and the prompts sent by the user making use of the program. 

## Assistant information

AssistantID: {{#assistant}}{{assistant}}{{/assistant}}{{^assistant}}No assistant was saved, use the --save-assistant option to save an assistant{{/assistant}}
ThreadID: {{#thread}}{{thread}}{{/thread}}{{^thread}}No thread was saved, use the --save-thread option to save a thread{{/thread}}

## Considerations and warnings about the AI usage to generate code

The main goal of the extension is to simplify the early stages of developing an extension for Github CLI (gh). It is not recommended to use the code generated by the language model without prior supervision regarding the quality and validity of the generated code, as it is well known that language models tend to suffer from hallucinations and may generate unnecessary or incorrect code if they are not able to fully understand the requirements.

The code generated by artificial intelligence should be used as a guide and inspiration to create the actual code for the extension. The gh-ai extension can be useful for exploring and testing different approaches, but never for generating a complete extension ready to be released to the public.

{{#options.debug}}
# InputObject

Json object created from the user's submitted information located on the `{{inputFile}}` file. 

```json
{{#inputObject}}
{{parseInputObject}}
{{/inputObject}}
```
{{/options.debug}}

# System Prompt

The purpose of this prompt is to indicate the context in which the LLM is going to work during the conversation. 

{{systemPrompt}}

# User prompts 

For each file requested by the user, its corresponding code has been generated. 
{{#userPrompts}}
{{#prompts}}

{{text}}

## Assistant Response
{{#response}}

{{response}}

{{/response}}
{{^response}}

The response to the requested task could not be extracted. This may be due to a problem during the conversation with the language model or reaching the prompt limit.

{{/response}}
{{#options.tokensVerbose}}
## Petition Usage

Total tokens used: **{{usage.total_tokens}}**
* Tokens used by the gh-ai generated prompt: **{{usage.prompt_tokens}}**.  
* Tokens used by the LLM to generate the answer: **{{usage.completion_tokens}}**.
{{/options.tokensVerbose}}
{{/prompts}}
{{#options.tokensVerbose}}
# Total Usage

Total tokens used to generate the {{#extension}}file{{/extension}}: **{{usage.totalTokens}}**.
* Total tokens used by the gh-ai generated prompts: **{{usage.totalPromptTokens}}**.  
* Total tokens used by the LLM to generate the answer: **{{usage.totalCompletionTokens}}**.

{{/options.tokensVerbose}}
{{/userPrompts}}