#!/usr/bin/env node
/**
 * Universidad de La Laguna
 * Escuela Superior de Ingeniería y Tecnología
 * Grado en Ingeniería Informática
 * Trabajo de Fin de Grado
 *
 * @author Raimon José Mejías Hernández  <alu0101390161@ull.edu.es>
 * @date 12/02/2024
 * @desc @TODO hacer la descripción
 */
import OpenAI from 'openai';
import { sleep } from 'openai/core.js';

import { CONSOLE_PROMPT, askYesNoQuestionToUser } from '../utils.js';
'use strict';

const DEFAULT_MODEL = 'gpt-3.5-turbo-0125';

/**
 * 
 * @param {OpenAI} openai 
 * @param {string} systemPrompt 
 * @param {string} llmModel 
 * @param {object} toolDescriptions 
 * @param {string} assistantID 
 * @returns {object}
 */
async function createOrRetreiveAssistant(openai, systemPrompt, llmModel, toolDescriptions, assistantID) { 

  const ASSISTANT_CONFIGURATION = {
    model: llmModel ?? DEFAULT_MODEL,
    name: 'gh-ai-assistant',
    description: 'Assistant generated by the gh-ai extension',
    tools: toolDescriptions,
    instructions: systemPrompt
  };

  if (assistantID) { // Si en el process.env existe un assistant ID, se extrae dicho assistant en lugar de crear uno nuevo  

    let assistant = await openai.beta.assistants.retrieve(assistantID);
    let askForUpdate = false;

    // Arrow function para sacar solo estas properties del objeto
    const unwrapper = (({model, name, description, instructions}) => {
       return {model, name, description, instructions};
    });

    const ASSISTANT_OLD_CONFIGURATION = unwrapper(assistant);

    for (const KEY of Object.keys(ASSISTANT_OLD_CONFIGURATION)) { // Recorre el objeto comprobando que tengan la misma configuración

      /** 
       * @TODO Ver como hacer para que se pueda comprobar que contiene las tools correctas
       * Ver como implementar un tag que mantega el ultimo tipo de commandType que ejecuto este assistant,
       * con eso ya se puede saber si se ha cambiado gran parte de la configuración 
      */
      if (ASSISTANT_CONFIGURATION[KEY] !== ASSISTANT_OLD_CONFIGURATION[KEY]) { 

        console.log(`${CONSOLE_PROMPT.WARNING}The old assistant configuration of "${assistant.name}" doesn't match with the new configuration readed from the inputObject.`);
        askForUpdate = true;
        break; 

      }

    }

    // En caso de que alguna configuración no coincida, preguntar al usuario si quiere actualizarlo
    if (askForUpdate) {
      await askYesNoQuestionToUser('  Do you want to update the assistant configuration?', async () => {
        console.log(`${CONSOLE_PROMPT.GH_AI}Updating assistant's configuration.`);
        assistant = await openai.beta.assistants.update(assistant.id, ASSISTANT_CONFIGURATION);
      });
    }

    return assistant;
  }

  // Si no existe process.env.ASSISTANT_ID se genera un nuevo asistente
  return await openai.beta.assistants.create(ASSISTANT_CONFIGURATION);
}

/**
 * 
 * @param {OpenAI} openai 
 * @param {string} threadID 
 */
async function createOrRetreiveThread(openai, threadID) {
  if (threadID) { 
    return await openai.beta.threads.retrieve(threadID); 
  } 
  return await openai.beta.threads.create();
}

/**
 * 
 * @param {OpenAI} openai 
 * @param {string} assistantID 
 * @param {string} threadID 
 * @param {string} outputDirectory 
 * @param {object} options 
 * @returns 
 */
async function call(openai, prompt, assistantID, threadID, runID = undefined) {

  const DELAY = 10000; // 10s
  const MAX_TRIES = 10;
  let currentTry = 0;
  let isToolOutput = false;

  if (!runID) { // En caso de que sea un tool output no se debe crear ningún mensaje nuevo

    // Añadir el mensaje a la conversación
    await openai.beta.threads.messages.create(
      threadID,
      { role: 'user', content: prompt }
    );
  
  }
  else {
    isToolOutput = true;
  }

  let callResult = {}

  // Repetir la llamada todas las veces necesarias hasta que MAX_TRIES sea alcanzado, se complete la run u ocurra un fallo
  while (currentTry < MAX_TRIES) {

    let run = {};

    // Si runID es especificado entonces se debe enviar el toolOutput a la IA
    if (isToolOutput) { 
      run = await openai.beta.threads.runs.submitToolOutputs(
        threadID,
        runID,
        prompt
      );

      // El envio se debe hacer solo una vez, en caso de que la run entre en rate_limit_exceeded se debe crear una nueva run y no volver a enviar el toolOutput. 
      isToolOutput = false; 
    }
    else {
      run = await openai.beta.threads.runs.create(
        threadID,
        { assistant_id: assistantID, }
      ); 
    }

    // Se guarda la nueva información de la run por cada intento.
    callResult.runID = run.id;
    callResult.runStatus = await checkRunStatus(openai, run.id, threadID);

    // La run termina siempre que no se llegue a un Rate_Limit
    if (callResult.runStatus !== 'rate_limit_exceeded') {
      if (callResult.runStatus === 'error') { // En caso de error, mostrarle información al usuario
        console.error(`${CONSOLE_PROMPT.ERROR}The API call couldn't be executed correctly, Generating Logs and stopping execution.`);  
      }
      return callResult;
    }

    // En caso de Rate Limit se vuelve a crear la run y se intenta de nuevo hasta que se alcance MAX_TRIES
    currentTry++;
    await sleep(DELAY);
  }

  // Si se alcanza MAX_TRIES El resultado se comporta como un error de la API
  callResult.runStatus = 'failed';
  console.error(`${CONSOLE_PROMPT.ERROR}The program used the max amount of calls but the API didn't respond, finishing execution.`);
  return callResult;
}

/**
 * 
 * @param {OpenAI} openai 
 * @param {string} runID 
 * @param {string} threadID 
 * @returns 
 */
async function checkRunStatus(openai, runID, threadID) {

  const LOG_STATUS = {
    rate_limit_exceeded: `${CONSOLE_PROMPT.WARNING}Rate limit exceeded, applying a 10s delay.`,
    failed:              `${CONSOLE_PROMPT.ERROR}The run failed while attempting to talk with the AI.`,
    expired:             `${CONSOLE_PROMPT.ERROR}The run reached the 10 minutes limit.`,
    queued:              `${CONSOLE_PROMPT.OPENAI}The run is still in queue. Waiting for the API to received.`,
    in_progress:         `${CONSOLE_PROMPT.OPENAI}The run is still active. Waiting for the API to response.`,
    cancelling:          `${CONSOLE_PROMPT.OPENAI}The run is being cancelled.`,
    cancelled:           `${CONSOLE_PROMPT.OPENAI}The run has been cancelled successfully.`,
    requires_action:     `${CONSOLE_PROMPT.OPENAI}The run requires an action from a tool. Waiting for the result.`,
    completed:           `${CONSOLE_PROMPT.OPENAI}The run has been completed, extracting the AI response.`
  };

  const DELAY = 3000; // 3s

  // Comprobar constantemente si la conversación ha terminado correctamente
  while (true) {

    // Comprobar la conversación en el momento actual
    const RUN = await openai.beta.threads.runs.retrieve(threadID, runID);
  
    console.log(LOG_STATUS[RUN.status]);

    switch (RUN.status) {

      case 'failed':
        if (RUN.last_error.code === 'rate_limit_exceeded') {
          console.log(LOG_STATUS[RUN.last_error.code]);
          return RUN.last_error.code;
        } 
        return 'failed';

      case 'expired':         return 'failed';   //
      case 'cancelled':       return 'failed';   // Estados finales Se simplifica los estados a 'Completado' 'Require una accion' 'Error' y 'Limite Excedido'
      case 'requires_action': return RUN.status; //
      case 'completed':       return RUN.status; //

      case 'queued':          break; //
      case 'in_progress':     break; // Estados intermedios, hay que seguir esperando para comprobar el estado final 
      case 'cancelling':      break; //

      default: // En caso de que la Run se encuentre en un estado desconocido. Error
        throw new OpenAI.APIError(-1, {
          type: 'no_status_support_error', 
          message: 'The run is in a not supported status.'
        });
    }

    await sleep(DELAY);
  }
}

export { createOrRetreiveAssistant, createOrRetreiveThread, call };