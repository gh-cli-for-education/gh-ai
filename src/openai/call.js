/**
 * Universidad de La Laguna
 * Escuela Superior de Ingeniería y Tecnología
 * Grado en Ingeniería Informática
 * Trabajo de Fin de Grado
 *
 * @author Raimon José Mejías Hernández  <alu0101390161@ull.edu.es>
 * @date 25/02/2024
 * @desc Contains the implementation of the OpenAI API Call
 */
import OpenAI from 'openai';
import { sleep } from 'openai/core.js';
import ora from 'ora';

import { CONSOLE_PROMPT, askYesNoQuestionToUser } from '../utils.js';
'use strict';

const DEFAULT_MODEL = 'gpt-3.5-turbo-0125';

/**
 * Given a configuration the fuction create or retreive an assistant, depends 
 * on the assistantID parameter.
 * @param {object} openai The OpenAI API object
 * @param {string} systemPrompt The instructions used to configure the assistant's context.
 * @param {string} llmModel The llm model used by the assistant
 * @param {object} toolDescriptions all the tools that can be used by the assistant.
 * @param {string} assistantID Used to retreive an already created assistant.
 * @returns {object} The assistant Object
 */
async function createOrRetreiveAssistant(openai, systemPrompt, llmModel, toolDescriptions, assistantID) { 

  const ASSISTANT_CONFIGURATION = {
    model: llmModel ?? DEFAULT_MODEL,
    name: 'gh-ai-assistant',
    description: 'Assistant generated by the gh-ai extension',
    tools: toolDescriptions,
    instructions: systemPrompt
  };

  if (assistantID) {

    let assistant = await openai.beta.assistants.retrieve(assistantID);
    let askForUpdate = false;

    // An arrow function used to extract the data from the object
    const unwrapper = (({model, name, description, instructions}) => {
       return {model, name, description, instructions};
    });

    const ASSISTANT_OLD_CONFIGURATION = unwrapper(assistant);

    // parse the object looking for a different configuration
    for (const KEY of Object.keys(ASSISTANT_OLD_CONFIGURATION)) { 

      if (ASSISTANT_CONFIGURATION[KEY] !== ASSISTANT_OLD_CONFIGURATION[KEY]) { 
        console.log(`${CONSOLE_PROMPT.WARNING}The old assistant configuration of "${assistant.name}" doesn't match with the new configuration readed from the inputObject.`);
        askForUpdate = true;
        break; 
      }

    }

    if (askForUpdate) {
      await askYesNoQuestionToUser('  Do you want to update the assistant configuration?', async () => {
        console.log(`${CONSOLE_PROMPT.GH_AI}Updating assistant's configuration.`);
        assistant = await openai.beta.assistants.update(assistant.id, ASSISTANT_CONFIGURATION);
      });
    }

    return assistant;
  }

  return await openai.beta.assistants.create(ASSISTANT_CONFIGURATION);
}

/**
 * Create or retreive a Thread object
 * @param {OpenAI} openai 
 * @param {string} threadID 
 */
async function createOrRetreiveThread(openai, threadID) {
  if (threadID) { 
    return await openai.beta.threads.retrieve(threadID); 
  } 
  return await openai.beta.threads.create();
}

/**
 * Call the OpenAI API to make the llm respond to a given prompt.
 * @param {object} openai 
 * @param {object} prompt 
 * @param {string} assistantID 
 * @param {string} threadID 
 * @param {object} executeTool 
 * @param {string} runID 
 * @returns {object}
 */
async function call(openai, prompt, assistantID, threadID, executeTool = undefined, runID = undefined) {

  const DELAY = 10000; // 10s
  const MAX_TRIES = 10;
  let currentTry = 0;

  // In case it is a tool ouput a new message is not created 
  if (!runID) {
    await openai.beta.threads.messages.create(
      threadID,
      { role: 'user', content: prompt }
    );
  }

  let callResult = {
    runID: undefined,
    runStatus: undefined,
  };


  let isToolOutput = true;
  while (currentTry < MAX_TRIES) {

    let run = {};

    if (runID !== undefined && isToolOutput) { 
      run = await openai.beta.threads.runs.submitToolOutputs(
        threadID,
        runID,
        prompt
      );
      // the tool input must be done just once 
      isToolOutput = false; 
    }
    else {
      run = await openai.beta.threads.runs.create(
        threadID,
        { 
          assistant_id: assistantID, 
          tool_choice: executeTool ?? 'none',
        }
      ); 
    }

    // Each try the run id is stored
    callResult.runID = run.id;

    let spinner = ora({ color: 'blue' }).start();
    callResult.runStatus = await checkRunStatus(openai, run.id, threadID, spinner);
    
    // The doesn't end if a rate limit is reached
    if (callResult.runStatus !== 'rate_limit_exceeded' || process.env.GRACEFUL_SHUTDOWN) {
      if (callResult.runStatus === 'error') {
        console.error(`${CONSOLE_PROMPT.ERROR}The API call couldn't be executed correctly, Generating Logs and stopping execution.`);  
      }
      spinner.stop();
      return callResult;
    }

    currentTry++;
    
    if (MAX_TRIES - currentTry <= MAX_TRIES * 0.5) {
      spinner.text += ` ${MAX_TRIES - currentTry} Attempts left before canceling execution.`;
    }

    await sleep(DELAY);
    spinner.stop();
  }

  // If the max try is reached then the run failed.
  callResult.runStatus = 'failed';
  console.error(`${CONSOLE_PROMPT.ERROR}The program used the max amount of calls but the API didn't respond, finishing execution.`);
  return callResult;
}

/**
 * Check the run status 
 * @param {OpenAI} openai 
 * @param {string} runID 
 * @param {string} threadID 
 * @param {Ora} spinner
 * @returns {string}
 */
async function checkRunStatus(openai, runID, threadID, spinner) {

  const DELAY = 2500; // 2.5s

  while (!process.env.GRACEFUL_SHUTDOWN) {

    const RUN = await openai.beta.threads.runs.retrieve(threadID, runID);
    
    switch (RUN.status) {

      case 'failed':
        if (RUN.last_error.code === 'rate_limit_exceeded') {
          spinner.color = 'magenta';
          spinner.text = `${CONSOLE_PROMPT.WARNING}Rate limit exceeded, applying a 10s delay.`;
          return RUN.last_error.code;
        }
        spinner.fail(`${CONSOLE_PROMPT.ERROR}The run failed while attempting to talk with the AI.`);        
        return 'failed';

      case 'expired':
        spinner.fail(`${CONSOLE_PROMPT.ERROR}The run reached the 10 minutes limit.`);
        return 'failed';

      case 'cancelled': 
        spinner.info(`${CONSOLE_PROMPT.OPENAI}The run has been cancelled successfully.`);      
        return 'failed';

      case 'requires_action':
        spinner.info(`${CONSOLE_PROMPT.OPENAI}The run requires an action from a tool. Waiting for the result.`);      
        return RUN.status;

      case 'completed': 
        spinner.succeed(`${CONSOLE_PROMPT.OPENAI}The run has been completed, extracting the AI response.`);
        return RUN.status;

      case 'queued':
        spinner.text = `${CONSOLE_PROMPT.OPENAI}The run is still in queue. Waiting for the API to received.`;
        break;

      case 'in_progress': 
        spinner.text = `${CONSOLE_PROMPT.OPENAI}The run is still active. Waiting for the API to response.`;
        break;

      case 'cancelling': 
        spinner.color = 'magenta';
        spinner.text = `${CONSOLE_PROMPT.OPENAI}The run is being cancelled.`;
        break;

      default: // In case there is an unknown status
        throw new OpenAI.APIError(-1, {
          type: 'no_status_support_error', 
          message: 'The run is in a not supported status.'
        });
    }

    await sleep(DELAY);
  }

  return 'gracefulShutdown';
}

export { createOrRetreiveAssistant, createOrRetreiveThread, call };