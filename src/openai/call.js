#!/usr/bin/env node
/**
 * Universidad de La Laguna
 * Escuela Superior de Ingeniería y Tecnología
 * Grado en Ingeniería Informática
 * Trabajo de Fin de Grado
 *
 * @author Raimon José Mejías Hernández  <alu0101390161@ull.edu.es>
 * @date 12/02/2024
 * @desc @TODO hacer la descripción
 */
import OpenAI from 'openai';
import { sleep } from 'openai/core.js';
import ora, { oraPromise } from 'ora';

import { CONSOLE_PROMPT, askYesNoQuestionToUser } from '../utils.js';
'use strict';

const DEFAULT_MODEL = 'gpt-3.5-turbo-0125';

/**
 * 
 * @param {OpenAI} openai 
 * @param {string} systemPrompt 
 * @param {string} llmModel 
 * @param {object} toolDescriptions 
 * @param {string} assistantID 
 * @returns {object}
 */
async function createOrRetreiveAssistant(openai, systemPrompt, llmModel, toolDescriptions, assistantID) { 

  const ASSISTANT_CONFIGURATION = {
    model: llmModel ?? DEFAULT_MODEL,
    name: 'gh-ai-assistant',
    description: 'Assistant generated by the gh-ai extension',
    tools: toolDescriptions,
    instructions: systemPrompt
  };

  if (assistantID) { // Si en el process.env existe un assistant ID, se extrae dicho assistant en lugar de crear uno nuevo  

    let assistant = await openai.beta.assistants.retrieve(assistantID);
    let askForUpdate = false;

    // Arrow function para sacar solo estas properties del objeto
    const unwrapper = (({model, name, description, instructions}) => {
       return {model, name, description, instructions};
    });

    const ASSISTANT_OLD_CONFIGURATION = unwrapper(assistant);

    // Recorre el objeto comprobando que tengan la misma configuración
    for (const KEY of Object.keys(ASSISTANT_OLD_CONFIGURATION)) { 

      /** 
       * @TODO Ver como hacer para que se pueda comprobar que contiene las tools correctas
       * Ver como implementar un tag que mantega el ultimo tipo de commandType que ejecuto este assistant,
       * con eso ya se puede saber si se ha cambiado gran parte de la configuración 
      */
      if (ASSISTANT_CONFIGURATION[KEY] !== ASSISTANT_OLD_CONFIGURATION[KEY]) { 
        console.log(`${CONSOLE_PROMPT.WARNING}The old assistant configuration of "${assistant.name}" doesn't match with the new configuration readed from the inputObject.`);
        askForUpdate = true;
        break; 
      }

    }

    // En caso de que alguna configuración no coincida, preguntar al usuario si quiere actualizarlo
    if (askForUpdate) {
      await askYesNoQuestionToUser('  Do you want to update the assistant configuration?', async () => {
        console.log(`${CONSOLE_PROMPT.GH_AI}Updating assistant's configuration.`);
        assistant = await openai.beta.assistants.update(assistant.id, ASSISTANT_CONFIGURATION);
      });
    }

    return assistant;
  }

  // Si no existe process.env.ASSISTANT_ID se genera un nuevo asistente
  return await openai.beta.assistants.create(ASSISTANT_CONFIGURATION);
}

/**
 * 
 * @param {OpenAI} openai 
 * @param {string} threadID 
 */
async function createOrRetreiveThread(openai, threadID) {
  if (threadID) { 
    return await openai.beta.threads.retrieve(threadID); 
  } 
  return await openai.beta.threads.create();
}

/**
 * 
 * @param {OpenAI} openai 
 * @param {string} assistantID 
 * @param {string} threadID 
 * @param {string} outputDirectory 
 * @param {object} options 
 * @returns 
 */
async function call(openai, prompt, assistantID, threadID, executeTool = undefined, runID = undefined) {

  const DELAY = 10000; // 10s
  const MAX_TRIES = 10;
  let currentTry = 0;
  let isToolOutput = false;

  if (!runID) { // En caso de que sea un tool output no se debe crear ningún mensaje nuevo

    // Añadir el mensaje a la conversación
    await openai.beta.threads.messages.create(
      threadID,
      { role: 'user', content: prompt }
    );
  
  }
  else {
    isToolOutput = true;
  }

  let callResult = {
    runID: undefined,
    runStatus: undefined,
  };

  // Repetir la llamada todas las veces necesarias hasta que MAX_TRIES sea alcanzado, se complete la run u ocurra un fallo
  while (currentTry < MAX_TRIES) {

    let run = {};

    // Si runID es especificado entonces se debe enviar el toolOutput a la IA
    if (isToolOutput) { 
      run = await openai.beta.threads.runs.submitToolOutputs(
        threadID,
        runID,
        prompt
      );

      // El envio se debe hacer solo una vez, en caso de que la run entre en rate_limit_exceeded se debe crear una nueva run y no volver a enviar el toolOutput. 
      isToolOutput = false; 
    }
    else {
      run = await openai.beta.threads.runs.create(
        threadID,
        { 
          assistant_id: assistantID, 
          tool_choice: executeTool ?? 'none',
        }
      ); 
    }

    // Se guarda la nueva información de la run por cada intento.
    callResult.runID = run.id;

    let spinner = ora({ color: 'blue' }).start();
    callResult.runStatus = await checkRunStatus(openai, run.id, threadID, spinner);
    
    if (process.env.GRACEFUL_SHUTDOWN) {
      return callResult;
    }

    // La run termina siempre que no se llegue a un Rate_Limit
    if (callResult.runStatus !== 'rate_limit_exceeded') {
      if (callResult.runStatus === 'error') { // En caso de error, mostrarle información al usuario
        console.error(`${CONSOLE_PROMPT.ERROR}The API call couldn't be executed correctly, Generating Logs and stopping execution.`);  
      }
      spinner.stop();
      return callResult;
    }

    // En caso de Rate Limit se vuelve a crear la run y se intenta de nuevo hasta que se alcance MAX_TRIES
    currentTry++;
    
    if (MAX_TRIES - currentTry <= MAX_TRIES * 0.5) {
      spinner.text += ` ${MAX_TRIES - currentTry} Attempts left before canceling execution.`;
    }

    await sleep(DELAY);
    spinner.stop();
  }

  // Si se alcanza MAX_TRIES El resultado se comporta como un error de la API
  callResult.runStatus = 'failed';
  console.error(`${CONSOLE_PROMPT.ERROR}The program used the max amount of calls but the API didn't respond, finishing execution.`);
  return callResult;
}

/**
 * 
 * @param {OpenAI} openai 
 * @param {string} runID 
 * @param {string} threadID 
 * @param {Ora} spinner
 * @returns 
 */
async function checkRunStatus(openai, runID, threadID, spinner) {

  const DELAY = 2500; // 2.5s

  // Comprobar constantemente si la conversación ha terminado correctamente
  while (!process.env.GRACEFUL_SHUTDOWN) {

    // Comprobar la conversación en el momento actual
    const RUN = await openai.beta.threads.runs.retrieve(threadID, runID);
    
    switch (RUN.status) {

      case 'failed':
        if (RUN.last_error.code === 'rate_limit_exceeded') {
          spinner.color = 'magenta';
          spinner.text = `${CONSOLE_PROMPT.WARNING}Rate limit exceeded, applying a 10s delay.`;
          return RUN.last_error.code;
        }
        spinner.fail(`${CONSOLE_PROMPT.ERROR}The run failed while attempting to talk with the AI.`);        
        return 'failed';

      case 'expired':
        spinner.fail(`${CONSOLE_PROMPT.ERROR}The run reached the 10 minutes limit.`);
        return 'failed';

      case 'cancelled': 
        spinner.info(`${CONSOLE_PROMPT.OPENAI}The run has been cancelled successfully.`);      
        return 'failed';

      case 'requires_action':
        spinner.info(`${CONSOLE_PROMPT.OPENAI}The run requires an action from a tool. Waiting for the result.`);      
        return RUN.status;

      case 'completed': 
        spinner.succeed(`${CONSOLE_PROMPT.OPENAI}The run has been completed, extracting the AI response.`);
        return RUN.status; //

      case 'queued':
        spinner.text = `${CONSOLE_PROMPT.OPENAI}The run is still in queue. Waiting for the API to received.`;
        break;

      case 'in_progress': 
        spinner.text = `${CONSOLE_PROMPT.OPENAI}The run is still active. Waiting for the API to response.`;
        break;

      case 'cancelling': 
        spinner.color = 'magenta';
        spinner.text = `${CONSOLE_PROMPT.OPENAI}The run is being cancelled.`;
        break;

      default: // En caso de que la Run se encuentre en un estado desconocido. Error
        throw new OpenAI.APIError(-1, {
          type: 'no_status_support_error', 
          message: 'The run is in a not supported status.'
        });
    }

    await sleep(DELAY);
  }

  return 'gracefulShutdown';
}

export { createOrRetreiveAssistant, createOrRetreiveThread, call };